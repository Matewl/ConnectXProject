{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from kaggle_environments import evaluate, make, utils\n",
    "from gym import spaces\n",
    "import gym\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_turn(board, mark, turn):\n",
    "    columns = 7\n",
    "    rows = 6\n",
    "    row = max([r for r in range(rows) if board[turn + (r * columns)] == 0])\n",
    "    board[turn + (row * columns)] = mark\n",
    "\n",
    "def is_win(board, column, mark):\n",
    "    \"\"\" Checks for a win. Taken from the Kaggle environment. \"\"\"\n",
    "\n",
    "    columns = 7\n",
    "    rows = 6\n",
    "    inarow = 3\n",
    "    row = min([r for r in range(rows) if board[column + (r * columns)] == mark])\n",
    "    def count(offset_row, offset_column):\n",
    "        for i in range(1, inarow + 1):\n",
    "            r = row + offset_row * i\n",
    "            c = column + offset_column * i\n",
    "            if (\n",
    "                    r < 0\n",
    "                    or r >= rows\n",
    "                    or c < 0\n",
    "                    or c >= columns\n",
    "                    or board[c + (r * columns)] != mark\n",
    "            ):\n",
    "                return i - 1\n",
    "        return inarow\n",
    "\n",
    "    return (\n",
    "            count(1, 0) >= inarow  # vertical.\n",
    "            or (count(0, 1) + count(0, -1)) >= inarow  # horizontal.\n",
    "            or (count(-1, -1) + count(1, 1)) >= inarow  # top left diagonal.\n",
    "            or (count(-1, 1) + count(1, -1)) >= inarow  # top right diagonal.\n",
    "    )\n",
    "\n",
    "def is_tie(board):\n",
    "    return not(any(mark == 0 for mark in board))\n",
    "\n",
    "def get_reward(board, column, mark):\n",
    "    if is_tie(board):\n",
    "        return 0.5\n",
    "    if is_win(board, column, mark):\n",
    "        return 1\n",
    "\n",
    "    return 0 # игра еще не закончена \n",
    "\n",
    "def find_action_taken_by_opponent(new_board, old_board, config):\n",
    "    \"\"\" Given a new board state and a previous one, finds which move was taken. Used for recycling tree between moves. \"\"\"\n",
    "    for i, piece in enumerate(new_board):\n",
    "        if piece != old_board[i]:\n",
    "            return i % config.columns\n",
    "    return -1  # shouldn't get here\n",
    "\n",
    "class MCTS_Node:\n",
    "    def __init__(self, board, mark, terminal, game_result = None, parent = None, parent_action = None) -> None:\n",
    "        self.board = board\n",
    "        self.mark = mark\n",
    "        self.terminal = terminal\n",
    "        self.game_result = game_result\n",
    "        self.parent = parent\n",
    "        self.parent_action = parent_action\n",
    "        self.children: list[MCTS_Node] = []\n",
    "        self.number_visits = 0\n",
    "        self.score = 0\n",
    "        self.untried_actions = self.available_moves()\n",
    "\n",
    "    def available_moves(self, board = None):\n",
    "        if board is None:\n",
    "            board = self.board\n",
    "\n",
    "        return [move for move in range(7) if board[move] == 0]\n",
    "    # def q(self):\n",
    "    #     wins = self._results[1]\n",
    "    #     loses = self._results[-1]\n",
    "    #     return wins - loses\n",
    "    def n(self):\n",
    "        return self.number_visits\n",
    "\n",
    "    def expand(self):\n",
    "        action = self.untried_actions.pop()\n",
    "        new_board = self.board.copy()\n",
    "\n",
    "        make_turn(new_board, self.mark, action)\n",
    "\n",
    "        score = get_reward(new_board, action, self.mark)\n",
    "        terminal = True\n",
    "\n",
    "        if score == 0:\n",
    "            terminal = False\n",
    "        child_node = MCTS_Node(\n",
    "            new_board, mark=3 - self.mark, terminal=terminal, game_result=score, parent=self, parent_action=action)\n",
    "        self.children.append(child_node)\n",
    "        return child_node \n",
    "    \n",
    "    def backpropagate(self, result):\n",
    "        self.number_visits += 1.\n",
    "        self.score += result\n",
    "        if self.parent:\n",
    "            self.parent.backpropagate(1 - result)\n",
    "\n",
    "    def rollout(self):\n",
    "        if self.terminal:\n",
    "            return self.game_result\n",
    "        mark = self.mark\n",
    "        new_board = self.board.copy()\n",
    "        action = self.rollout_policy(self.available_moves())\n",
    "        make_turn(new_board,  mark, action)\n",
    "        score = get_reward(new_board, action, mark)\n",
    "\n",
    "        while  score == 0:\n",
    "            mark = 3 - mark\n",
    "            action = self.rollout_policy(self.available_moves(new_board))\n",
    "\n",
    "            make_turn(new_board, mark, action)\n",
    "            score = get_reward(new_board, action, mark)\n",
    "        if mark == self.mark:\n",
    "            return score\n",
    "        return 1 - score\n",
    "    \n",
    "    def rollout_policy(self, available_moves): # may be better?\n",
    "        return available_moves[np.random.randint(len(available_moves))] #may be here\n",
    "\n",
    "    def simulate(self):\n",
    "        if self.terminal:\n",
    "            return self.game_result\n",
    "        return 1 - self.rollout()\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.untried_actions) == 0\n",
    "\n",
    "    def best_child(self, c_param=0.1):    \n",
    "        choices_weights = [(c.score / c.n()) + c_param * np.sqrt((2 * np.log(self.n()) / c.n())) for c in self.children]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "    \n",
    "    def _tree_policy(self):\n",
    "        current_node = self\n",
    "        while not current_node.is_terminal_node():\n",
    "            \n",
    "            if not current_node.is_fully_expanded():\n",
    "                return current_node.expand()\n",
    "            else:\n",
    "                current_node = current_node.best_child()\n",
    "        return current_node\n",
    "    \n",
    "    def best_action(self):\n",
    "        simulation_no = 100\n",
    "            \n",
    "        for i in range(simulation_no):\n",
    "            \n",
    "            v = self._tree_policy()\n",
    "            reward = v.rollout()\n",
    "            v.backpropagate(reward)\n",
    "        \n",
    "        return self.best_child(c_param=0.)\n",
    "    \n",
    "    def expand_and_simulate_child(self):\n",
    "        self.expand()\n",
    "        simulation_score = self.children[-1].simulate()\n",
    "        self.children[-1].backpropagate(simulation_score)\n",
    "\n",
    "    def tree_single_run(self):\n",
    "        if self.terminal:\n",
    "            self.backpropagate(self.game_result)\n",
    "            return\n",
    "        if not self.is_fully_expanded():\n",
    "            self.expand_and_simulate_child()\n",
    "            return\n",
    "        self.best_child().tree_single_run()\n",
    "            \n",
    "    def choose_child_via_action(self, action):\n",
    "        for child in self.children:\n",
    "            if child.parent_action == action:\n",
    "                return child\n",
    "        return None\n",
    "\n",
    "def MCTS_agent(observation, configuration):\n",
    "    \"\"\"\n",
    "    Connect X agent based on MCTS.\n",
    "    \"\"\"\n",
    "    \n",
    "    import random\n",
    "    import math\n",
    "    import time\n",
    "    global current_state  # so tree can be recycled\n",
    "    board = observation.board\n",
    "    mark = observation.mark\n",
    "    init_time = time.time()\n",
    "    T_max = configuration.timeout - 0.34  # time per move, left some overhead\n",
    "    print(T_max)\n",
    "\n",
    "    # If current_state already exists, recycle it based on action taken by opponent\n",
    "    try:  \n",
    "        current_state = current_state.choose_child_via_action(\n",
    "            find_action_taken_by_opponent(board, current_state.board, configuration))\n",
    "        current_state.parent = None  # make current_state the root node, dereference parents and siblings\n",
    "        \n",
    "    except:  # new game or other error in recycling attempt due to Kaggle mechanism\n",
    "        current_state = MCTS_Node(board=board,mark= mark, terminal=False)\n",
    "   \n",
    "    # Run MCTS iterations until time limit is reached.\n",
    "    while time.time() - init_time <= T_max:\n",
    "        current_state.tree_single_run()\n",
    "        \n",
    "    current_state = current_state.best_child()\n",
    "    return current_state.parent_action"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
