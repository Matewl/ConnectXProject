{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from kaggle_environments import evaluate, make, utils, register\n",
    "import telebot\n",
    "from telebot import types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_turn(board, mark, turn):\n",
    "    columns = 7\n",
    "    rows = 6\n",
    "    row = max([r for r in range(rows) if board[turn + (r * columns)] == 0])\n",
    "    board[turn + (row * columns)] = mark\n",
    "    \n",
    "def bad_move(board, turn):\n",
    "    columns = 7\n",
    "    rows = 6\n",
    "    if len([r for r in range(rows) if board[turn + (r * columns)] == 0]) == 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_win(board, column, mark):\n",
    "    columns = 7\n",
    "    rows = 6\n",
    "    current_board = np.array(board.copy())\n",
    "\n",
    "    def move_board(board, r, c):\n",
    "        new_board = np.zeros(board.shape)\n",
    "        rows, cols = new_board.shape\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                new_board[i][j] = board[(i + rows - r) % rows][(j + cols - c) % cols]\n",
    "        return new_board\n",
    "    \n",
    "    def is_win_simple(board_, mark):\n",
    "        \"\"\" Checks for a win. Taken from the Kaggle environment. \"\"\"\n",
    "        if board_[0][0] == mark and board_[0][1] == mark and board_[0][2] == mark and board_[0][3] == mark:\n",
    "            return True\n",
    "        if board_[0][0] == mark and board_[1][0] == mark and board_[2][0] == mark and board_[3][0] == mark:\n",
    "            return True\n",
    "        if board_[0][0] == mark and board_[1][1] == mark and board_[2][2] == mark and board_[3][3] == mark:\n",
    "            return True\n",
    "        if board_[3][0] == mark and board_[2][1] == mark and board_[1][2] == mark and board_[0][3] == mark:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    for k in range(rows):\n",
    "        for m in range(columns):\n",
    "            new_board = move_board(current_board.reshape(rows, columns), k, m)\n",
    "            if is_win_simple(new_board, mark):\n",
    "                return True\n",
    "            \n",
    "    return False\n",
    "\n",
    "\n",
    "def is_tie(board):\n",
    "    return not(any(mark == 0 for mark in board))\n",
    "\n",
    "def get_reward(board, column, mark):\n",
    "    if is_tie(board):\n",
    "        return 0.5\n",
    "    if is_win(board, column, mark):\n",
    "        return 1\n",
    "\n",
    "    return 0 # игра еще не закончена \n",
    "\n",
    "def find_action_taken_by_opponent(new_board, old_board, config):\n",
    "    \"\"\" Given a new board state and a previous one, finds which move was taken. Used for recycling tree between moves. \"\"\"\n",
    "    for i, piece in enumerate(new_board):\n",
    "        if piece != old_board[i]:\n",
    "            return i % config.columns\n",
    "    return -1  # shouldn't get here\n",
    "\n",
    "class MCTS_Node:\n",
    "    def __init__(self, board, mark, terminal, game_result = None, parent = None, parent_action = None) -> None:\n",
    "        self.board = board\n",
    "        self.mark = mark\n",
    "        self.terminal = terminal\n",
    "        self.game_result = game_result\n",
    "        self.parent = parent\n",
    "        self.parent_action = parent_action\n",
    "        self.children: list[MCTS_Node] = []\n",
    "        self.number_visits = 0\n",
    "        self.score = 0\n",
    "        self.untried_actions = self.available_moves()\n",
    "\n",
    "    def available_moves(self, board = None):\n",
    "        if board is None:\n",
    "            board = self.board\n",
    "\n",
    "        return [move for move in range(7) if board[move] == 0]\n",
    "    # def q(self):\n",
    "    #     wins = self._results[1]\n",
    "    #     loses = self._results[-1]\n",
    "    #     return wins - loses\n",
    "    def n(self):\n",
    "        return self.number_visits\n",
    "\n",
    "    def expand(self):\n",
    "        action = self.untried_actions.pop()\n",
    "        new_board = self.board.copy()\n",
    "\n",
    "        make_turn(new_board, self.mark, action)\n",
    "\n",
    "        score = get_reward(new_board, action, self.mark)\n",
    "        terminal = True\n",
    "\n",
    "        if score == 0:\n",
    "            terminal = False\n",
    "        child_node = MCTS_Node(\n",
    "            new_board, mark=3 - self.mark, terminal=terminal, game_result=score, parent=self, parent_action=action)\n",
    "        self.children.append(child_node)\n",
    "        return child_node \n",
    "    \n",
    "    def backpropagate(self, result):\n",
    "        self.number_visits += 1.\n",
    "        self.score += result\n",
    "        if result == 0:\n",
    "            self.score -= 5\n",
    "        if self.parent:\n",
    "            self.parent.backpropagate(1 - result)\n",
    "\n",
    "    def rollout(self):\n",
    "        if self.terminal:\n",
    "            return self.game_result\n",
    "        mark = self.mark\n",
    "        new_board = self.board.copy()\n",
    "        action = self.rollout_policy(self.available_moves())\n",
    "        make_turn(new_board,  mark, action)\n",
    "        score = get_reward(new_board, action, mark)\n",
    "\n",
    "        while  score == 0:\n",
    "            mark = 3 - mark\n",
    "            action = self.rollout_policy(self.available_moves(new_board))\n",
    "\n",
    "            make_turn(new_board, mark, action)\n",
    "            score = get_reward(new_board, action, mark)\n",
    "        if mark == self.mark:\n",
    "            return score\n",
    "        return 1 - score\n",
    "    \n",
    "    def rollout_policy(self, available_moves): # may be better?\n",
    "        return available_moves[np.random.randint(len(available_moves))] #may be here\n",
    "\n",
    "    def simulate(self):\n",
    "        if self.terminal:\n",
    "            return self.game_result\n",
    "        return 1 - self.rollout()\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.untried_actions) == 0\n",
    "\n",
    "    def best_child(self, c_param=0.1):    \n",
    "        choices_weights = [(c.score / c.n()) + c_param * np.sqrt((2 * np.log(self.n()) / c.n())) for c in self.children]\n",
    "        return self.children[np.argmax(choices_weights)]\n",
    "    \n",
    "    def _tree_policy(self):\n",
    "        current_node = self\n",
    "        while not current_node.is_terminal_node():\n",
    "            \n",
    "            if not current_node.is_fully_expanded():\n",
    "                return current_node.expand()\n",
    "            else:\n",
    "                current_node = current_node.best_child()\n",
    "        return current_node\n",
    "    \n",
    "    def best_action(self):\n",
    "        simulation_no = 100\n",
    "            \n",
    "        for i in range(simulation_no):\n",
    "            \n",
    "            v = self._tree_policy()\n",
    "            reward = v.rollout()\n",
    "            v.backpropagate(reward)\n",
    "        \n",
    "        return self.best_child(c_param=0.)\n",
    "    \n",
    "    def expand_and_simulate_child(self):\n",
    "        self.expand()\n",
    "        simulation_score = self.children[-1].simulate()\n",
    "        self.children[-1].backpropagate(simulation_score)\n",
    "\n",
    "    def tree_single_run(self):\n",
    "        if self.terminal:\n",
    "            self.backpropagate(self.game_result)\n",
    "            return\n",
    "        if not self.is_fully_expanded():\n",
    "            self.expand_and_simulate_child()\n",
    "            return\n",
    "        self.best_child().tree_single_run()\n",
    "            \n",
    "    def choose_child_via_action(self, action):\n",
    "        for child in self.children:\n",
    "            if child.parent_action == action:\n",
    "                return child\n",
    "        return None\n",
    "\n",
    "def MCTS_agent(observation, configuration):\n",
    "    \"\"\"\n",
    "    Connect X agent based on MCTS.\n",
    "    \"\"\"\n",
    "    import random\n",
    "    import math\n",
    "    import time\n",
    "    global current_state  # so tree can be recycled\n",
    "    board = observation.board\n",
    "    mark = observation.mark\n",
    "    init_time = time.time()\n",
    "    EMPTY = 0\n",
    "    T_max = 35  # time per move, left some overhead\n",
    "    Cp_default = 13\n",
    "\n",
    "    \n",
    "    for turn in [move for move in range(7) if board[move] == 0]:\n",
    "        new_board = board.copy()\n",
    "        make_turn(new_board, 3 - mark, turn)\n",
    "        if is_win(new_board, turn, 3 - mark):\n",
    "            return turn\n",
    "    # If current_state already exists, recycle it based on action taken by opponent\n",
    "    try:  \n",
    "        current_state = current_state.choose_child_via_action(\n",
    "            find_action_taken_by_opponent(board, current_state.board, configuration))\n",
    "        current_state.parent = None  # make current_state the root node, dereference parents and siblings\n",
    "        \n",
    "    except:  # new game or other error in recycling attempt due to Kaggle mechanism\n",
    "        current_state = MCTS_Node(board=board,mark= mark, terminal=False)\n",
    "   \n",
    "    # Run MCTS iterations until time limit is reached.\n",
    "    while time.time() - init_time <= T_max:\n",
    "        current_state.tree_single_run()\n",
    "        \n",
    "    current_state = current_state.best_child()\n",
    "    return current_state.parent_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EMPTY = 0\n",
    "\n",
    "def interpreter(state, env):\n",
    "    active = state[0] if state[0].status == \"ACTIVE\" else state[1]\n",
    "\n",
    "    # Specification can fully handle the reset.\n",
    "    if env.done:\n",
    "        return state\n",
    "\n",
    "    # Isolate the active and inactive agents.\n",
    "    active = state[0] if state[0].status == \"ACTIVE\" else state[1]\n",
    "    inactive = state[0] if state[0].status == \"INACTIVE\" else state[1]\n",
    "    if active.status != \"ACTIVE\" or inactive.status != \"INACTIVE\":\n",
    "        active.status = \"DONE\" if active.status == \"ACTIVE\" else active.status\n",
    "        inactive.status = \"DONE\" if inactive.status == \"INACTIVE\" else inactive.status\n",
    "        return state\n",
    "\n",
    "    # Keep the board in sync between both agents.\n",
    "    board = active.observation.board\n",
    "    inactive.observation.board = board\n",
    "    action = active.action\n",
    "    mark = active.observation.mark\n",
    "\n",
    "    # Illegal move by the active agent.\n",
    "    if bad_move(board, action):\n",
    "        active.status = f\"Invalid move: {action}\"\n",
    "        inactive.status = \"DONE\"\n",
    "        return state\n",
    "\n",
    "    # Mark the position.\n",
    "    make_turn(board, mark, action)\n",
    "\n",
    "    # Check for a win.\n",
    "    if is_win(board, action, mark):\n",
    "        active.reward = 1\n",
    "        active.status = \"DONE\"\n",
    "        inactive.reward = 0\n",
    "        inactive.status = \"DONE\"\n",
    "    \n",
    "        return state\n",
    "\n",
    "    # Check for a tie.\n",
    "    if is_tie(board):\n",
    "        active.status = \"DONE\"\n",
    "        inactive.status = \"DONE\"\n",
    "        return state\n",
    "\n",
    "    # Swap active and inactive agents to switch turns.\n",
    "    active.status = \"INACTIVE\"\n",
    "    inactive.status = \"ACTIVE\"\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_board(board):\n",
    "    print(\"\\n|-----+-----+-----+-----+-----+-----+-----|\")\n",
    "    for i in range(6):\n",
    "        print('|  ', end = '')\n",
    "        for j in range(7):\n",
    "            print(board[i * 7 + j], end='  |  ')\n",
    "        print(\"\\n|-----+-----+-----+-----+-----+-----+-----|\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renderer(state, env):\n",
    "    # row_bar = \"\\n---+---+---+---+---+---+---\\n\"\n",
    "    # marks = [\" \", \"X\", \"O\"]\n",
    "    def print_board(board):\n",
    "        for i in range(6):\n",
    "            for j in range(7):\n",
    "                print(board[i * 7 + j], end='   ')\n",
    "            print('\\n')\n",
    "    # def print_pos(pos):\n",
    "    #     str = \"\"\n",
    "    #     if pos % 3 == 0 and pos > 0:\n",
    "    #         str += row_bar\n",
    "    #     if pos % 3 != 0:\n",
    "    #         str += \"|\"\n",
    "    #     return str + f\" {marks[state[0].observation.board[pos]]} \"\n",
    "\n",
    "    # return \"\".join(print_pos(p) for p in range(42))\n",
    "    print_board(state[0].observation.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "def random_agent(obs):\n",
    "    a = choice([c for c in range(len(obs.board)) if obs.board[c] == EMPTY])\n",
    "    return a % 7 \n",
    "\n",
    "\n",
    "def reaction_agent(obs):\n",
    "    # Connect 3 in a row to win.\n",
    "    \n",
    "    print_board(obs.board)# No 3-in-a-rows, return random unmarked.\n",
    "    action = int(input())\n",
    "    return choice(list(filter(lambda m: m[1] == EMPTY, enumerate(obs.board))))[0]\n",
    "\n",
    "\n",
    "agents = {\"random\": random_agent, \"reaction\": reaction_agent, 'MCTS': MCTS_agent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_env = make(\"connectx\", debug=True)\n",
    "\n",
    "specification = true_env.specification.copy()\n",
    "specification[\"name\"] = \"ConnectXOnTor\"\n",
    "specification[\"title\"] = \"ConnectXOnTor\"\n",
    "specification[\"description\"] = \"ConnectX but On Tor\"\n",
    "specification['observation']['board']['default'] = [0] * 42\n",
    "specification['configuration']['timeout']['default'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "register(specification[\"name\"], {\n",
    "    \"agents\": agents,\n",
    "    \"interpreter\": interpreter,\n",
    "    \"renderer\": renderer,\n",
    "    \"specification\": specification,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_board(board):\n",
    "    s = ''\n",
    "    s += \"\\n|-----+-----+-----+-----+-----+-----+-----|\\n\"\n",
    "    for i in range(6):\n",
    "        s += '|  '\n",
    "        for j in range(7):\n",
    "            s += str(board[i * 7 + j]) + '  |  '\n",
    "        s += \"\\n|-----+-----+-----+-----+-----+-----+-----|\\n\"\n",
    "    return '```' + s + '```'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = {\"random\": random_agent, \"reaction\": reaction_agent, 'MCTS': MCTS_agent}\n",
    "register(specification[\"name\"], {\n",
    "    \"agents\": agents,\n",
    "    \"interpreter\": interpreter,\n",
    "    \"renderer\": renderer,\n",
    "    \"specification\": specification,\n",
    "})\n",
    "env = make(specification[\"name\"], debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGBotForConnectX:\n",
    "    def __init__(self) -> None:\n",
    "        self.board_for_bot =  [0] * 42\n",
    "        self.bot = telebot.TeleBot('7054763245:AAFT3zRXmKc_wqQY8eUOyU4UUr2MRXsmQAI')\n",
    "        self.obs = None\n",
    "        self.state = None\n",
    "        self.env = make('ConnectXOnTor', debug=True)\n",
    "        self.config = env.configuration\n",
    "    def do_all(self):\n",
    "        @self.bot.message_handler(commands=['start'])\n",
    "        def start(message):\n",
    "\n",
    "            self.bot.send_message(message.from_user.id, 'Это бот для игры Connect4 на торе. Каждый ход - это число от 1 до 7. \\\n",
    "                                   \\nБоту требуется 10-15 секунд, чтобы сделать ход',  parse_mode=\"Markdown\")            \n",
    "            self.bot.send_message(message.from_user.id, 'Если хочешь ходить первым, введи 1 \\nЕсли хочешь ходить вторым, введи 2', \n",
    "                                   parse_mode=\"Markdown\")            \n",
    "            self.bot.register_next_step_handler(message, choose_colour)\n",
    "        def incorrect_choose_color(message):\n",
    "            self.bot.send_message(message.from_user.id, 'Некорректный ввод')\n",
    "            self.bot.register_next_step_handler(message, choose_colour)\n",
    "        def choose_colour(message):\n",
    "            self.state = self.env.reset(2)[0]\n",
    "            self.obs = self.state['observation']\n",
    "\n",
    "            if message.text == '2':\n",
    "                turn = MCTS_agent(self.obs, self.config)\n",
    "                self.state = self.env.step([turn, 200])[0]\n",
    "                self.obs = self.state['observation']\n",
    "                self.bot.send_message(message.from_user.id, draw_board(self.obs['board']),  parse_mode=\"Markdown\")\n",
    "                self.bot.register_next_step_handler(message, user_turn_second)\n",
    "                \n",
    "            elif message.text == '1':\n",
    "                self.bot.send_message(message.from_user.id, draw_board(self.obs['board']),  parse_mode=\"Markdown\")\n",
    "                self.bot.send_message(message.from_user.id, 'сделай первый ход',  parse_mode=\"Markdown\")\n",
    "                self.bot.register_next_step_handler(message, user_turn_first)\n",
    "            else: \n",
    "                self.bot.register_next_step_handler(message, incorrect_choose_color)\n",
    "\n",
    "        def incorrect_turn(message):\n",
    "            self.bot.send_message(message.from_user.id, 'Некорректный ход')\n",
    "            self.bot.register_next_step_handler(message, user_turn_second)\n",
    "\n",
    "        def user_turn_second(message):\n",
    "            available_moves = [move for move in range(7) if self.obs['board'][move] == 0]\n",
    "            action_by_user = int(message.text) - 1\n",
    "\n",
    "            if action_by_user not in available_moves:\n",
    "                self.bot.register_next_step_handler(message, incorrect_turn)\n",
    "\n",
    "            self.state = self.env.step([200, action_by_user])[0]\n",
    "            self.obs = self.state['observation']\n",
    "            self.bot.send_message(message.from_user.id, draw_board(self.obs['board']),  parse_mode=\"Markdown\")\n",
    "            if self.state['status'] == 'DONE':\n",
    "                self.bot.send_message(message.from_user.id, 'You win!')\n",
    "                self.bot.send_message(message.from_user.id, 'выбери номер хода, если хочешь сыграть еще')\n",
    "                self.bot.register_next_step_handler(message, choose_colour)\n",
    "            else:\n",
    "                turn = MCTS_agent(self.obs, self.config)\n",
    "                print(turn)\n",
    "                self.state = self.env.step([turn, 200])[0]\n",
    "                self.obs = self.state['observation']\n",
    "                self.bot.send_message(message.from_user.id, draw_board(self.obs['board']),  parse_mode=\"Markdown\")\n",
    "                if self.state['status'] == 'DONE':\n",
    "                    self.bot.send_message(message.from_user.id, 'You lose!')\n",
    "                    self.bot.send_message(message.from_user.id, 'выбери номер хода, если хочешь сыграть еще')\n",
    "                    self.bot.register_next_step_handler(message, choose_colour)\n",
    "                else:\n",
    "                    self.bot.register_next_step_handler(message, user_turn_second)\n",
    "        def user_turn_first(message):\n",
    "            action_by_user = int(message.text) - 1\n",
    "            self.state = self.env.step([action_by_user, 200])[0]\n",
    "            self.obs = self.state['observation']\n",
    "            self.bot.send_message(message.from_user.id, draw_board(self.obs['board']),  parse_mode=\"Markdown\")\n",
    "            if self.state['status'] == 'DONE':\n",
    "                self.bot.send_message(message.from_user.id, 'You win!')\n",
    "                self.bot.send_message(message.from_user.id, 'выбери номер хода, если хочешь сыграть еще')\n",
    "                self.bot.register_next_step_handler(message, choose_colour)\n",
    "            else:\n",
    "                turn = MCTS_agent(self.obs, self.config)\n",
    "                print(turn)\n",
    "                self.state = self.env.step([200, turn])[0]\n",
    "                self.obs = self.state['observation']\n",
    "                self.bot.send_message(message.from_user.id, draw_board(self.obs['board']),  parse_mode=\"Markdown\")\n",
    "                if self.state['status'] == 'DONE':\n",
    "                    self.bot.send_message(message.from_user.id, 'You lose!')\n",
    "                    self.bot.send_message(message.from_user.id, 'выбери номер хода, если хочешь сыграть еще')\n",
    "                    self.bot.register_next_step_handler(message, choose_colour)\n",
    "                else:\n",
    "                    self.bot.register_next_step_handler(message, user_turn_first)\n",
    "\n",
    "        self.bot.polling()    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'timeout': 100, 'columns': 7, 'rows': 6, 'inarow': 4, 'steps': 1000}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = TGBotForConnectX()\n",
    "a.do_all()\n",
    "env.configuration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
